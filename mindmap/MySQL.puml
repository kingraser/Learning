@startmindmap
*[#lightgrey] MySQL
    *[#lightpink] 1基础篇
        *[#lightgreen] 基础架构:一条查询如何执行
            *[#lightblue] server层
                *_ 连接器 管理连接/校验权限
                *_ 查询缓存 8.0版本后,该功能取消
                *_ 分析器 语法分析
                *_ 优化器 优化方案
                *_ 执行器
            *[#lightblue] 存储引擎
                *_ InnoDB/MyISAM/Memory
        *[#lightgreen] 日志系统:一条更新如何执行
            *[#orange] redo log(引擎层/物理日志)
                *_ WAL(Write Ahead Logging)
                *_ Crash Safe
                *_ write pos/checkpoint 循环写入
            *[#orange] binlog(Server层/逻辑日志)
                *_ 追加写入 不会覆盖
            *[#orange] 两阶段提交
                *_ (引擎)写redo log prepare阶段
                *_ (执行器)写binlog
                *_ (引擎)提交事务 处于commit状态
        *[#lightgreen] 事务隔离:为什么改了看不见
            *[#orange] 隔离级别
                *_ 读未提交
                *_ 读提交(Oracle默认)
                *_ 可重复读
                *_ 串行化
            *[#orange] 隔离实现
                *_ MVCC(Multi Version Concurrency Control)记录有版本 undo-log
                *_ 长事务会导致undo log过大/占用锁资源
            *[#orange] 事务启动方法
                *_ 显式启动事务语句 begin/start transaction\n commit/rollback
                *_ set autocommit 0自动开启事务1需要显式启动事务
                *_ commit work and chain(autocommit=1的情况下)
            *[#orange] 避免长事务
                *[#lightblue] 应用开发端
                    *_ 设置autocommit=1
                    *_ 去除不必要的只读事务
                    *_ 控制语句执行时间 set max_execution_time
                *[#lightblue] DB端
                    *_ 监控长事务 information_schema.innodb_trx表
                    *_ 使用pt-kill工具
                    *_ 业务功能测试阶段输出general_log分析
                    *_ 设置innoDB_undo_tablespaces(回滚段表空间数量)为2
        *[#lightgreen] 深入浅出索引 上
            *[#orange] 索引模型
                *_ 哈希表 不适用区间查询
                *_ 有序数组 不适合频繁更新数据
                *_ 二叉搜索树 需要保持平衡
                *_ B+树 适用于磁盘存储
            *[#orange] InnoDB索引
                *_ 索引组织表
                *_ B+树
                *_ 主键索引和非主键索引的差别:非主键索引的叶子实际是主键值
            *[#orange] 索引维护
                *_ 插入数据的维护
                *_ 页分裂和合并
            *[#orange] 自增主键的选择
                *_ 适合有序插入场景
                *_ 减少存储空间占用
            *[#orange] 重建索引的方法
                *_ drop index(primary key)/add index(primary key)
        *[#lightgreen] 深入浅出索引 下
            *[#orange] 覆盖索引
                *_ 减少树的搜索次数
                *_ 提升查询性能
            *[#orange] 最左前缀原则
                *_ 利用最左前缀定位记录
                *_ 支持联合索引最左N个字段
                *_ 支持String索引最左M个字符
            *[#orange] 索引下推
                *_ 利用索引中字段先做判断
                *_ 减少回表
        *[#lightgreen] 全局锁和表锁:加字段的阻碍
            *[#orange] 全局锁
                *_ FTWRL(Flush Table With Read Lock)
                *_ 适用场景:全库逻辑备份
                *_ 需要注意备份一致性问题
                *_ mysqldump使用--single transaction参数(InnoDB引擎支持)
                * readOnly方式 VS FTWRL方式
                    *_ readOnly可能被用来判断主从库
                    *_ FTWRL如果客户端异常断开会释放锁
            *[#orange] 表锁
                *[#lightblue] 表锁
                    *_ lock tables...read/write
                    *_ unlock tables
                *[#lightblue] 元数据锁(meta data lock)
                    *_ 读锁 操作加读锁
                    *_ 写锁 改表结构加写锁
                    *_ MDL锁的互斥性 读/写锁之间,写锁之间互斥
                    *_ 长事务和MDL锁 MDL锁在事务提交才释放
                    *_ 安全的给小表加字段 alter 添加wait_time 字段
        *[#lightgreen] 行锁功过:如何减少性能影响
            *[#orange] 两阶段锁协议
                *_ 需要时加上,事务结束才释放
                *_ 安排事务的语句顺序 最影响并发的语句放在最后
            *[#orange] 死锁和死锁检测
                *_ 死锁超时 innodb_lock_wait_timeout(默认50s)
                *_ 死锁检测 innodb_deadlock_detect(on)
                *_ 死锁检测会消耗大量CPU 复杂度O(N^2) N为竞争的并发线程数
            *_ 优化锁冲突 逻辑上变成多行
            *_ 删除10_000条数据,一个连接里循环20次每次删除500好于直接删(长事务)和20个连接每个删500(锁竞争)
        *[#lightgreen] 事务到底隔离还是不隔离
            *[#orange] 事务启动
                *_ begin/start transaction命令并不是一个事务的起点,在执行到它们之后的第一个操作InnoDB表的语句,事务才真正启动(trx_id生成)
                *_ 想要马上启动事务,适用start transaction with consistent snapshot
            *[#orange] consistent read view
                *_ 事务启动时生成
            *[#orange] InnoDB行数据版本
                *_ 多版本数据,用row trx_id区分
            *[#orange] 快照在MVCC中的工作原理
                *_ 事务操作根据隔离级别找到对应读版本的数据
            *[#orange] 数据版本可见性规则
                *_ if (未提交 or 已提交但在视图创建后) then 不可见
            *[#orange] update时 当前读 + 两阶段提交
    *[#lightpink] 3特别放送
        *[#lightgreen] 林晓斌:我的MySQL的心路历程
    *[#lightpink] 4结束语
        *[#lightgreen] 点线面网,一起构建MySQL知识网络
left side
    *[#lightpink] 2实战篇
        *[#lightgreen] 普通索引/唯一索引:如何选择
            *[#orange] 查询性能 差异微乎其微,只有key正好在某一页最后一位才有差异
            *[#orange] 更新性能 更新目标页不在内存中,使用changeBuffer,普通索引省磁盘操作效率高
            *[#orange] changeBuffer
                *_ 适用于写多读少的场景,如果写完马上读,还有反作用
                *_ redo log减少随机写,changeBuffer减少随机读
                *_ 断电不影响,靠redo-log
                *_ merge不一定马上flush
        *[#lightgreen] 为什么MySQL会选错索引
            *[#orange] 优化器逻辑
                *_ 扫描行数判断
                *[#lightblue] 索引统计信息
                    *_ 基数(cardinality一个索引上不同值的个数)和区分度
                    *_ 统计方法 默认统计N个页不同值取平均*索引的页面数;更新超过1/M时,重新索引统计
                    *_ 统计信息更新机制 analyze table
            *[#orange] 索引异常的处理
                *_ 适用force index
                *_ 修改语句引导优化器
                *_ 新增/delete索引
        *[#lightgreen] 怎么给字符串字段加索引
            *_ 完整索引 完整;占用空间大
            * 前缀索引
                *_ 占用小;区分度损失,扫描数增加
                *_ 建议先判断区分度损失,再确定具体长度
                *_ 有覆盖索引时不推荐
            *_ 倒序存储 适用于尾部区分度更大的case,比如身份证号;不支持范围
            *_ hash字段索引 占用小;不支持范围
        *[#lightgreen] 为什么MySQL会"抖"一下
            *[#orange] 原因
                *_ 内存和磁盘数据不一致,被称为脏页
                *_ 刷脏页flush时,性能下降
            *[#orange] 刷脏页控制逻辑
                *[#lightblue] 什么时候flush
                    *_ redo log满了
                    *_ 内存满了
                    *_ 空闲了
                    *_ 正常关闭
                *[#lightblue] flush策略
                    *_ innodb_io_capacity磁盘能力,建议设置为磁盘IOPS(可以由fio工具测试)
                    *_ 两因素:脏页比例和redo log待写入的大小
                    *_ innodb_flush_neighbors,是否flush相邻页,机械硬盘适用,SSD建议关闭
            *[#orange] 监控脏页比例
                *_ Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total
        *[#lightgreen] 为什么表数据删掉一半,表文件大小不变
            *[#orange] 表数据存储方式
                *[#lightblue] innodb_file_per_table
                    *_ off 放在系统共享表空间,和数据字典一起
                    *_ on 每个表独立存储.ibd后缀的文件;5.6.6版本后默认on
            *[#orange] 数据删除流程
                *_ 标记数据页(可以任意复用)和记录(符合范围的)为可复用
                *_ insert也可以导致数据空洞
            *[#orange] 减小数据空洞方式:重建表
                *[#lightblue] alter table A engine=InnoDB
                    *_ 5.5版本前,更改期间会丢失修改 server层 copy
                    *_ 5.6版本后 不丢失更改 InnoDB内部 inplace
                    *_ 加MDL读锁:可以update,但不能改表结构
            *[#orange] 其他重建方法
                *_ analyze table 重新统计索引;加MDL读锁
                *_ optimize table: recreate+analyze
        *[#lightgreen] count(*)慢怎么办
            *[#orange] 如何得来
                *_ MyISAM直接记下一个数字,需要时返回
                *_ show table status很快,但不准(基于索引页采样估计)
                *_ InnoDB count(*) 扫表,准确(因为要MVCC)但慢
                *_ count(*)最优
            *[#orange] 学习MyISAM:事务写表计数
        *[#lightgreen] 日志和索引相关问题答疑
            *[#orange] 两阶段提交
                *_ 崩溃时如何恢复:redo-log prepare时需要查看binlog,完整则提交/不完整回滚
                *_ 如何判断binlog完整, statement格式有commit,row格式有XID event;5.6.2后还有binlog-checksum
                *_ redo-log和binlog如何关联:XID
                *_ binlog完整为什么算提交,因为binlog可能被从库使用了已经
                * 为什么要两个日志
                    *_ 历史原因MySQL引擎不支持崩溃恢复,InnoDB引入后,既然binlog没有恢复能力,就使用InnoDB自带的redo-log
                    *_ 只用binlog行不行:功能上redo-log有checkpoint,之前的记录必定已经刷盘,binlog则无,所以只用binlog无法恢复数据页
                    *_ 只用redo-log行不行:无法归档
                *_ redo-log尽量设置大一点
                *_ 刷盘是从内存,而不是redo-log
                *_ redo-log buffer是什么:数据先写到内存(多线程共享),prepare时再持久化到redo-log文件里
        *[#lightgreen] "order by"如何工作
            *[#orange] 全字段排序
                *_ 初始化sort buffer
                *_ 查到数据放入sort buffer
                *_ 排序并取limit返回
            *[#orange] rowId排序(需要回表,但省sort buffer空间)
                *_ 初始化sort buffer
                *_ 查到排序字段和主键放入sort buffer
                *_ 排序并取limit,回表拿到数据返回
        *[#lightgreen] 如何正确显示随机消息
            *_ 从一个单词表中随机选出三个单词
            * select word from words order by rand() limit 3;
                *_ 用到内存临时表
                *_ 对于InnoDB优先用全字段排序,减少回表
                *_ tmp_table_size这个配置限制了内存临时表的大小,超过时,转磁盘临时表
                *_ 5.6版本后引入优先队列算法
            * 随机方法1
                *_ 取得这个表的主键id的最大值M和最小值N
                *_ 用随机函数生成一个最大值到最小值之间的数X=(M-N)*rand()+N
                *_ 取不小于X的第一个ID的行
                *_ ID可能有空洞,所以不同行概率不同
            * 随机方法2
                *_ 取得整个表的行数,并记为C
                *_ 取得Y=floor(C*rand()).floor函数在这里的作用,就是取整数部分
                *_ 再用limitY,1取得一行
                *_ 因为获取总行数需要扫描;limit需要跳过,所以性能比1差
        *[#lightgreen] 为什么这些SQL逻辑相同,性能差异巨大
            *_ 条件字段函数操作:函数操作破坏了索引的有序性
            *_ 隐式类型转换 字符串和数字比较,字符串先转换成数字
            *_ 隐式字符编码转换 utf8mb4是utf8的超集
        *[#lightgreen] 为什么只查一行数据,执行这么慢
            *[#orange] 查询长时间不返回
                *_ 等MDL锁  show processlist
                *_ 等flush
                *_ 等行锁
            *[#orange] 查询慢
                *_ 全表扫描 慢查询日志
                *_ 扫描一行但执行慢 可能是一致性读 lock in share mode可以拿到当前值
                *_ 加锁读
        *[#lightgreen] 幻读是什么,有什么问题
            *_ 同事务里,同一查询不同时刻行数不一致
            * 解决方法:gap lock(只在可重复读级别)
                *_ 只和insert冲突,gap lock间不冲突
                *_ 和行锁合称next-key lock,前开后闭区间
                *_ 容易死锁,影响并发
        *[#lightgreen] 为什只改一行的语句,锁这么多
            *[#orange] 加锁原则
                *_ 基本单位是next-key lock,加在索引上(有时需要绕过覆盖索引优化)
                *_ 查找过程访问到的对象才会加锁
                *_ 索引上等值查询,给唯一索引加锁时,退化为行锁
                *_ 索引上等值查询,向右遍历时,最后一个值不满足等值条件的时候,next-key lock退化为间隙锁
                *_ delete时用limit可以缩小锁范围
                *_ 加锁两阶段:先加间隙锁,再加行锁
        *[#lightgreen] 有哪些饮鸩止渴提高性能的方法
            *[#orange] 短链接风暴
                *_ 连接数暴涨;max_connections参数
                *_ 断开不工作的线程(show processlist):先断事务外的(information_schema库的innodb_trx表),后断事务内的(kill connection+id)
                *_ 减少连接损耗,如取消权限验证
            *[#orange] 慢查询
                *[#lightblue] 索引没设计好
                    *_ 备库set sql_log_bin=off,然后alter table加索引
                    *_ 主备切换后重复上述操作
                    *_ 考虑ghost这样的方案(建临时表,然后切换)
                *[#lightblue] SQL语句没写好
                    *_ query_rewrite:把输入的语句改成另外一种模式
                *[#lightblue] MySQL选错索引
                    *_ force index
                    *_ 事先测试
            *[#orange] QPS突增
                *_ ip白名单限制;账号限制;重写SQL语句
        *[#lightgreen] 怎么保证数据不丢
            *[#orange] binlog
                *_ 先写binlog cache,事务提交时写bin log文件,并清空cache
                *_ binlog cache每个线程一个,binlog_cache_size参数控制大小,超过暂存磁盘
                *_ write指写入文件系统page cache,fsync是持久化到硬盘
                *[#lightblue] sync_binlog参数
                    *_ 0表示每次提交事务只write,不fsync
                    *_ 1表示都fsync
                    *_ N(N>1)表示每次都write,累计N后fsync;若主机异常重启会丢失N个事务的binlog日志
            *[#orange] redo-log
                *[#lightblue] 先写redo-log buffer(全局共用),事务没提交也可能持久化到硬盘
                    *_ innoDB有一个后台进程,每隔一秒,write&fsync
                    *_ redo-log buffer达到innodb_log_buffer_size一半的时候,write
                    *_ 并行的事务提交时,顺带持久化到硬盘
                *[#lightblue] innodb_flush_log_at_trx_commit
                    *_ 0表示只写redo-log buffer
                    *_ 1表示直接持久化到磁盘
                    *_ 2表示只写page cache(主机掉电会丢失数据)
            *[#orange] group commit机制
                *_ log sequence number lsn
                *_ 一起提交
                * binlog
                    *_ binlog_group_commit_sync_delay 多少微秒后fsync
                    *_ binlog_group_commit_sync_no_delay_count累计多少次
                    *_ 两者或的关系,使用会增加响应时间
                *_ WAL机制性能两方面:顺序写+组提交
            *[#orange] 问题
                *_ update后idb文件没变化;可能是WAL机制导致
                *_ 为何binlog每线程自己维护,redo-log buffer全局共用;binlog(逻辑日志)不能被打断
                * 什么业务场景下innodb_flush_log_at_trx_commit/sync_binlog不都为1
                    *_ 可预见的业务高峰期
                    *_ 备库延迟
                    *_ 用备库恢复主库的副本,应用binlog过程
                    *_ 批量导入数据
                    *_ 可以设置innodb_flush_logs_at_trx_commit=2;sync_binlog=1000
        *[#lightgreen] 怎么保证主备一致
            *_ binlog格式statement(逻辑,省数据,但同步可能导致不一致)/row(具体,但占用大,可以恢复数据)/mixed(mysql自动判断)
            *_ binlog有上下文,比如now()函数会set timestamp,来解决主备同步延迟时的数据一致性问题,所以不能直接复制语句
            *_ binlog做主备同步,server id防止循环复制;注意server id变化可能导致问题,比如2节点改3节点
        *[#lightgreen] 怎么保证高可用
            *[#orange] 主备延迟
                *_ 延迟过大的核心是备库消费能力小于主库生产能力
                *_ 主备库有性能差异
                *_ 备库压力大,比如跑一些统计查询
                *_ 大事务:在主库执行时间就长;比如delete大量数据/大表DDL
                *_ 备库的并行复制能力
            *[#orange] 切换策略
                *[#lightblue] 可靠性优先
                    * 步骤
                        *_ 1确保延迟时间少于某个预期值
                        *_ 2主库改为只读
                        *_ 3等待从库延迟变为0
                        *_ 4从库改成可以读写
                        *_ 5业务请求切换到从库
                    *_ 延迟时间内服务不可用;数据一致性好
                *[#lightblue] 可用性优先
                    *_ 直接上面4和5
                    *_ 可能数据不一致,binlog row格式更容易发现不一致
        *[#lightgreen] 备库为什么会延迟好几个小时
            *[#orange] 多线程消费主库binlog
                *[#lightblue] 原则
                    *_ 操作同一行的不同事务不能分配到不同worker
                    *_ 同一个事务不能分配到不同worker
                *_ 按库分worker
                *[#lightblue] 基于group commit
                    *_ 同一组提交的事务,一定不会修改同一行
                    *_ 主库上可以并行的事务,从库也一定可以并行
                    *_ 基于commit id将一组事务分发到不同worker
                    * 问题
                        *_ 主库一组事务提交时,下一组事务处于执行中状态
                        *_ 从库只会等前一组事务执行完毕,执行下一组事务
                        *_ 所以从库的并发度不如主库,容易被大事务拖住
                *[#lightblue] 提升并发
                    *_ 同时prepare的事务可以并行
                    *_ 处于prepare的事务和处于commit的事务也可以并行
                    * binlog-transaction-dependency-tracking
                        *_ COMMIT_ORDER:根据prepare和commit判断是否可以并行策略
                        *_ WRITESET:对于事务操作的每一行,计算hash,判断有无交集,若没有则可并行(必须有主键,且没有外键)
                        *_ WRITESET_SESSION:在WRITESET基础上,多了一个约束:主库上同一个线程先后执行的事务,在从库上要保证相同的执行顺序
        *[#lightgreen] 主库出问题了,从库怎么办
            *_ case:一主多从,主库A切换为A',其余从库如何将要同步到主库切换到A'
            *[#lightblue] 基于GTID(Global Transaction ID)
                *_ server_uuid(实例启动时生成,全局唯一):gno(整数,从1开始,事务提交时分配并加一)
                *_ gtid_mode=on和enforce_gtid_consistency=on
                *_ 生成两种case:gtid_next=automatic(自动加一分配);set gtid_next='current_gtid'(gtid已经存在则ignore,若有则用设定值)
                *_ CHANGE MASTER TO MASTER_HOST=$host_name MASTER_PORT=$port MASTER_USER=$user_name MASTER_PASSWORD=$password master_auto_position=1
                *_ 执行start slave,从库把gtid set发给主库,主库判断是自己的子集与否.若是则同步从库没有的部分;若不是则报错
        *[#lightgreen] 读写分离有哪些坑
            *_ 两种架构:1client直连从库(少一层性能好,结构简单;变更会有client感知);2client连proxy(client友好;结构复杂)
            *[#lightblue] 过期读
                *_ 走master
                *_ sleep
                * 判断主备延迟
                    *_ show slave status:seconds_behind_master
                    *_ 对比点位
                    *_ 对比GTID set
                * semi sync:有从库ack了再给client返回
        *[#lightgreen] 如何判断一个数据库是不是出问题了
            *[#lightblue] select 1
                *_ 优点:简单
                *_ 缺点:只能判断出库的进程还在,不能判断主库没有问题
                *_ 例如:innodb_thread_concurrency已经满了,但是select 1可以正常返回
                *_ innodb_thread_concurrency默认为0表示不限制,推荐64-128
                *_ 锁等待状态,并发计数减一
            *[#lightblue] 自定义一个表health & select * from health
                *_ 优点:能查出并发过多导致数据库不可用的情况
                *_ 缺点:查不出binlog导致磁盘满了的情况,因为系统可以正常读
            *[#lightblue] 自定义一个表health & update health set updateTime = now()
                *_ 优点:能查出binlog占满磁盘的情况
                *_ 缺点:主备同步时可能因为update导致行冲突
                *_ 改进方法,多行数据,以server id为主键,每台机器更新自己的行
            *[#lightblue] 内部统计
                *_ 上面的方法可以判断状态,但是不好判断update慢\n 比如IO利用率100%的场景,检测语句仍有可能很快返回\n 因为检测语句资源占用不大,如果拿到资源就能很快返回
                *_ performance_schema库file_summary_by_event_name表;开启慢10%
                *_ 可以通过update setup_instruments set ENABLED='YES', Timed='YES'来控制开关
        *[#lightgreen] 答疑二:用动态的观点看加锁
            *_ 加锁是扫描时一个个加上去的,所以为了避免死锁,访问同一组资源的访问顺序尽量相同
            *_ 如何查看死锁:show engine innodb status命令LATESTDETECTED DEADLOCK
            *_ innoDB会自动选择回滚成本更小的方案避免死锁
            *_ 间隙锁是由后继的记录定义的,所以删除记录可能导致锁范围扩大,空表锁住所有
        *[#lightgreen] 误删数据后怎么办
            *[#lightblue] delete误删行
                *_ 使用Flashback恢复,需要binlog_format=row和binlog_row_image=FULL
                *_ 不建议直接在主库上操作,先在临时库上恢复,确认后再恢复到主库;防止数据二次破坏
                *_ 预防:sql_safe_updates参数设置为on,无where或where没有索引字段,报错
                *_ 预防:sql上线前评审
            *[#lightblue] drop/truncate误删表&库
                *_ 需要定期的全量备份和binlog备份
                *_ 找到最近的全量备份,再用binlog备份复原
                *_ 加速恢复:mysqlbinlog命令可以通过-database参数指定库
                *_ 记得跳过误删语句
                * 比较慢
                    *_ 因为误删表的话,最好只重放该表而不是库,但mysqlbinlog不能指定表
                    *_ mysqlbinglog单线程
                * 加速方法
                    *_ 从备份恢复出临时实例,将该实例设置为线上备库的从库
                    *_ start slave之前,change replication filter replicate_do_table = (tbl_name)
                    *_ 这样可以并行
                    *_ 如果备库binlog不全,可以手动放入再重启,即可重新识别binlog文件
                * 延迟恢复备库
                    *_ CHANGE MASTER TO MASTER_DELAY=N命令,可以指定这个备库持续保持跟主库有N秒的延迟
                    *_ 这样最多追N的时间即可恢复
                *_ 预防:账号分离,常见开发账号只有DML权限没有DDL权限
                *_ 预防:操作规范:如删除必须先改名,比如后面加to_be_deleted\n 一段时间无问题,才必须从管理系统删除\n 管理系统也只能删带有后缀的表or库
            *[#lightblue] rm命令误删mysql实例
                *_ 删掉节点:整个集群选个新主库
                *_ 删掉集群:备份跨机房/跨城市
            *[#lightblue] 预防
                *_ 四个脚本:备份/执行/验证/回滚
                *_ 用chatrr +i给重要文件加保护,这样root也没法直接删除
        *[#lightgreen] 为什么有kill不掉的语句
            *_ kill query+线程id;终止语句
            *_ kill connection+线程id;connection可以缺省,终止线程连接
            *[#lightblue] kill后的操作
                *_ 1将线程状态改为kill_query
                *_ 2给执行线程发一个信号
            *[#lightblue] 为何kill了却还能在show processlist结果里看到
                * 1线程执行中有一些判断逻辑,发现状态kill了,再进入终止逻辑
                    *_ 如IO压力大,IO函数一直没有返回,不能即使判断线程状态
                *_ 2如果处于等待状态,必须是可以被唤醒的线程
                * 3执行终止逻辑需要一个过程
                    *_ 超大事务回滚
                    *_ 大查询回滚,清理临时文件
                    *_ DDL执行到最后阶段,被kill需要删除中间临时文件,可能受IO资源影响耗时久
            *[#lightblue] client ctrl+c
                *_ MySQL是停等协议,还没有返回的时候,不能继续下一个命令
                *_ client另外启动一个连接,再执行kill query命令
            *[#lightblue] client 库里表多就建立连接慢
                * 客户端有命令表名补全功能
                    *_ show databases;
                    *_ show tables;
                    *_ 内存建立hashTable;所以表多会慢
                *_ 用-A参数可以取消
                * 用-quick参数
                    *_ 跳过表名补全功能
                    *_ mysql_use_result(本地不缓存)
                    *_ 不会把执行命令记录到本地历史文件
            *[#lightblue] kill慢时
                *_ 调大并发度,或者停掉别的线程,让出位子给这个线程执行
                *_ 若受限于IO等资源执行慢,只能减少系统压力
                *_ 若kill,导致事务回滚很慢,应该等吗?应该,因为不等,直接关闭,重启后,该有的操作一样会继续
        *[#lightgreen] 我查这么多数据,会不会把数据库内存打爆
            *[#lightblue] 流程
                *_ 获取一行,写到net_buffer中.大小是由参数net_buffer_length定义的,默认是16k
                *_ 重复获取行,直到net_buffer写满,调用网络接口发出去
                *_ 如果发送成功,就清空net_buffer,然后继续取下一行,并写入net_buffer
                *_ 如果发送函数返回EAGAIN或WSAEWOULDBLOCK,就表示本地网络栈(socket send buffer)写满了,进入等待.直到网络栈重新可写,再继续发送
            *_ 由于边读边发,所以client可能会成为瓶颈(乃至导致长事务,导致server端能力下降);状态Sending to client/Sending data只是正在执行的意思
            *_ InnoDB使用LRU算法更新BufferPool,内存命中率一般需要99%以上,innodb_buffer_pool_size推荐物理内存的60%-80%
            *_ 通过分代,防止大表扫描导致内存命中率下降
        *[#lightgreen] 到底可不可以用join
            *[#lightblue] 流程
                *_ 优化器选择小表作为驱动表, 如果用straight join则可以手动指定
                *_ 小表指的是总数据量,因此有可能表A100行,1个字段;表B虽然50行,但是有3个字段,通算表A是小表
                *_ 从驱动表1读出一行,去被驱动表2里找到相应数据
                *_ 加入结果集,并重复上述过程
            *[#lightblue] 如何从被驱动表找数据
                *_ 能用索引的话用索引(这种情况可以join)
                * 不能能用索引的话(这种join尽量不用,可能导致内存命中率下降)
                    * 将驱动表数据全部放入内存
                        *_ 放不下的case,分段放
                        *_ join_buffer_size控制,默认256k
                    *_ 扫描被驱动表并与内存中数据join
        *[#lightgreen] join语句如何优化
            *[#lightblue] Multi-Range Read(MRR)优化
                *_ 根据索引a,定位到满足条件的记录,将id值放入read_rnd_buffer中;(read_rnd_buffer_size参数控制,满了则循环操作)
                *_ 将read_rnd_buffer中的id进行递增排序;
                *_ 排序后的id数组,依次到主键id索引中查记录,并作为结果返回.
            *[#lightblue] Batched Key Access(BKA)优化
                *_ 驱动表数据放到join_buffer
                *_ 用MRR方式从被驱动表找数据
            *[#lightblue] 想用join,但被驱动表无索引,加索引又因为是低频业务不值得操作,怎么办
                *_ 将被驱动表对应数据查出,放在临时表
                *_ 临时表加索引再join
            *[#lightblue] hash_join
                *_ join操作只能轮询是慢的根源,能hash会快很多
                *_ MySQL 8.0支持hash join了
                *_ 更早的版本只能手动在程序里模拟
            *[#lightblue] 三表join语句如何加索引
                *_ select * from t1 join t2 on(t1.a=t2.a) join t3 on (t2.b=t3.b) where t1.c>=X and t2.c>=Y and t3.c>=Z;
                *_ 在t1.c>=X、t2.c>=Y、t3.c>=Z这三个条件里,选择一个经过过滤以后,数据最少的那个表,作为第一个驱动表.此时,可能会出现如下两种情况
                * 第一种情况,如果选出来是表t1或者t3,那剩下的部分就固定了
                    *_ t1是驱动表,t1->t2->t3,此时在被驱动表上t2.a和t3.b建索引
                    *_ t3是驱动表,t3->t2->t1,此时在被驱动表上t2.b和t1.a建索引
                *_ 如果选出来的第一个驱动表是表t2的话,由于t2既可以先join t1,又可以join t3,所以选更小的表驱动
        *[#lightgreen] 为什么临时表可以重名
            *[#lightblue] 临时表的特性
                * 临时表和内存表的不同
                    *_ 内存表create table ... engine=memory,数据在内存,重启被清空,但表结构还在
                    *_ 临时表可以用任何引擎,写数据时写盘,重启自动回收
                *_ create temporary table ...
                *_ 只能被创建的session访问,对其他线程不可见
                *_ 可以和普通表重名
                *_ sessionA同时有同名临时表和普通表时,show create以及增删改查访问的临时表
                *_ show tables不显示临时表
            *[#lightblue] 临时表应用
                *_ 跨库查询:各库查询结果放入临时表,再进行后续操作
                *_ 复杂查询的优化:如join查询,被驱动表没有索引,可以将查到数据放入临时表,临时表加索引,再join
            *[#lightblue] 临时表为什么可以重名
                *_ 表定义文件,放在临时文件目录下,#sql{进程id}_{线程id}_序列号.frm
                * 数据文件
                    *_ 5.6及之前,临时文件目录下,相同前缀的.ibd文件
                    *_ 5.7开始,有一个临时文件空间,专门存放临时文件的数据,不需要再创建idb文件(防止频繁使用临时表,创建/删除文件,带来大量磁盘性能消耗)
                * table_def_key
                    *_ 普通表库名+表名
                    *_ 临时表在普通表基础上,加server_id+thread_id
            *[#lightblue] 临时表和主备复制
                *_ binlog format=row时,临时表语句不进入binlog
                *_ binlog format=statement/mixed时,临时表操作语句才进入binlog
            *_ 临时表可以alter table改名,但不能直接rename
        *[#lightgreen] 什么时候使用内部临时表
            *[#lightblue] union
                *_ 内部临时表上面有唯一索引,实现去重语义
                *_ 若union all,则无去重,则不用内部临时表
            *[#lightblue] group by
                *_ 内部临时表上面有唯一索引,实现分组语义
                *_ 返回默认排序,若无需排序,可以加order by null
                *_ 若group by字段有索引,则无需内部临时表
                *_ select后加SQL_BIG_RESULT(hint),可直接使用磁盘数组:获得所有值后排序,再顺序统计group by,而非B+树的内部临时表
            *_ 如果可以一边读数据一边得到结果,就不需要额外内存,否则就需要,来保存中间结果
            *_ join_buffer是无序数组,sort_buffer是有序数组,临时表是二维表结构
            *_ 内存临时表按照扫描顺序,磁盘临时表则按照主键顺序
        *[#lightgreen] 都说innoDB好,那还要不要用Memory引擎
            *_ 内存表的数据部分以数组的方式单独存放,而主键id索引里,存的是每个数据的位置.主键id是hash索引,索引上的key并不是有序的
            *_ InnoDB 表的数据总是有序存放的,而内存表的数据就是按照写入顺序存放的
            *_ 当数据文件有空洞的时候,InnoDB 表在插入新数据的时候,为了保证数据有序性,只能在固定的位置写入新值,而内存表找到空位就可以插入新值
            *_ 数据位置发生变化的时候,InnoDB 表只需要修改主键索引,而内存表需要修改所有索引
            *_ InnoDB表用主键索引查询时需要走一次索引查找,用普通索引查询的时候,需要走两次索引查找.而内存表没有这个区别,所有索引的“地位”都是相同的
            *_ InnoDB 支持变长数据类型,不同记录的长度可能不同;内存表不支持Blob和Text字段,并且即使定义了varchar(N),实际也当作char(N),也就是固定长度字符串来存储,因此内存表的每行数据长度相同
            *_ 主键hash索引,不支持范围搜索.可以使用alter table t1 add index a_btree_index using btree (id)新建b树索引
            *_ 不支持行锁,只有表锁
            *_ 因为重启数据丢失,担心主备不一致,重启后binlog记录delete from t1
            *_ 适用于用户临时表case
        *[#lightgreen] 自增主键为什么不是连续的
            *[#lightblue] 自增值存在哪里
                *_ MyISAM 在数据文件
                *_ InnoDB在内存,若重启,设为current_max()+1;8.0版本后,持久化到redo-log
            *[#lightblue] 自增值修改机制
                *_ 若为0/null/未制定,设定为自增值
                *_ 否则设定为指定值
                * 然后变更自增值;
                    *_ if(指定值小于自增值) then do noting
                    *_ else 从auto_increment_offset(默认1)开始,以auto_increment_increment(默认1)为步长,持续叠加,直到找到第一个大于指定值的值,作为新的自增值
            *[#lightblue] 不连续的原因
                *_ 主键冲突
                *_ 事务回滚:为什么自增值不能回退?因为可能有别的事务更新了自增值
                *_ 批量插入(insert select)(不清楚申请多少,实际是类似java hashmap resize,二进制翻倍申请)
            *[#lightblue] 自增锁的优化
                * innodb_autoinc_lock_mode参数,版本5.1引入,默认1
                    *_ 0:和5.0一样,语句结束才释放锁
                    *_ 1:普通insert,申请后就释放;insert select,语句结束才释放(应用场景:主从复制,binlog是statement格式)
                    *_ 2:申请就释放
        *[#lightgreen] insert语句的锁为什么这么多
            *[#lightblue] insert select在可重复读隔离级别+binlog是statement格式时,会对select表所有扫描到的记录和间隙加锁
                *_ 因为如果不加锁,主从复制场景,由于可重复读,主库看不到事务执行中新插入的记录
                *_ 但是binlog同步到从库,statement格式,从库会插入事务执行中新插入的数据,导致数据不一致
            *[#lightblue] insert t select t
                *_ insert into t(c,d)  (select c+1, d from t force index(c) order by c desc limit 1)
                *_ 上述语句会使用临时表&锁全表
                *_ 原因是这类一边遍历数据,一边更新数据的情况,如果读出来的数据直接写回原表,就可能在遍历过程中,读到刚刚插入的记录,新插入的记录如果参与计算逻辑,就跟语义不符
                *_ 可以用临时表优化\n create temporary table temp_t(c int,d int) engine=memory;\n insert into temp_t  (select c+1, d from t force index(c) order by c desc limit 1);\n insert into t select * from temp_t;\n drop table temp_t;
            *[#lightblue] insert唯一键冲突
                *_ 冲突后,会在冲突索引上加读锁(可能导致死锁)
                *_ 这样可以防止该记录被别的事务删掉,维护可重复读的语义
            *[#lightblue] insert on duplicate key update
                *_ 冲突后,会在冲突索引上加next-key lock写锁
                *_ 多个唯一键冲突,update和第一个索引冲突的行
        *[#lightgreen] 如何最快复制一张表
            *[#lightblue] mysqldump
                *_ mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql
                *_ –single-transaction的作用是,在导出数据的时候不需要对表db1.t加表锁,而是使用START TRANSACTION WITH CONSISTENT SNAPSHOT的方法
                *_ –add-locks设置为0,表示在输出的文件结果里,不增加"LOCKTABLEStWRITE;"
                *_ –no-create-info的意思是,不需要导出表结构
                *_ –set-gtid-purged=off表示的是,不输出跟GTID相关的信息
                *_ –result-file指定了输出文件的路径,其中client表示生成的文件是在客户端机器上的
                *_ 如果希望生成的文件中一条INSERT语句只插入一行数据的话,可以在执行mysqldump命令时,加上参数–skip-extended-insert
                *_ 在db2库上执行:mysql -h127.0.0.1 -P13000  -uroot db2 -e "source /client_tmp/t.sql"
            *[#lightblue] 导出csv
                * select * from db1.t where a>900 into outfile '/server_tmp/t.csv';
                    *_ 文件保存在server端
                    *_ into outfile指定了文件的生成位置(/server_tmp/),这个位置必须受参数secure_file_priv的限制.参数secure_file_priv的可选值和作用分别是
                        *_ 如果设置为empty,表示不限制文件生成的位置,这是不安全的设置
                        *_ 如果设置为一个表示路径的字符串,就要求生成的文件只能放在这个指定的目录,或者它的子目录
                        *_ 如果设置为 NULL,就表示禁止在这个MySQL实例上执行 select … into outfile操作
                    *_ 不会覆盖文件,若已有同名文件则报错
                    *_ 这条命令生成的文本文件中,原则上一个数据行对应文本文件的一行.但是,如果字段中包含换行符,在生成的文本中也会有换行符.不过类似换行符、制表符这类符号,前面都会跟上“\”这个转义符,这样就可以跟字段之间、数据行之间的分隔符区分开
                    *_ 不会生成表结构文件
                    *_ mysqldump提供了一个–tab 参数,可以同时导出表结构定义文件和csv数据文件
                    *_ mysqldump -h$host -P$port -u$user ---single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --tab=$secure_file_priv
                    *_ $secure_file_priv定义的目录下,创建一个t.sql文件保存建表语句,同时创建一个t.txt文件保存CSV数据
                * load data infile '/server_tmp/t.csv' into table db2.t;
                    *_  若binlog为statement,则csv会写入binlog
                    *_  不加'local',是读取服务端的文件,这个文件必须在secure_file_priv指定的目录或子目录下
                    *_  加上'local',读取的是客户端的文件,只要mysql客户端有访问这个文件的权限即可.这时候,MySQL客户端会先把本地文件传给服务端,然后执行上述的load data流程.
            *[#lightblue] 物理copy
                *_  假设我们现在的目标是在db1库下,复制一个跟表t相同的表r
                *_  执行create table r like t,创建一个相同表结构的空表
                *_  执行alter table r discard tablespace,这时候r.ibd文件会被删除
                *_  执行flush table t for export,这时候db1目录下会生成一个t.cfg文件(t只读)
                *_  在db1目录下执行cp t.cfg r.cfg;cp t.ibd r.ibd;这两个命令(这里需要注意的是,拷贝得到的两个文件,MySQL进程要有读写权限);
                *_  执行unlock tables,这时候t.cfg文件会被删除;(t释放读锁)
                *  执行alter table r import tablespace,将这个r.ibd文件作为表r的新的表空间,由于这个文件的数据内容和t.ibd是相同的,所以表r中就有了和表t相同的数据
                    *_  在执行import tablespace的时候,为了让文件里的表空间id和数据字典中的一致,会修改r.ibd的表空间id.而这个表空间id存在于每一个数据页中.
                    *_  因此,如果是一个很大的文件(比如TB级别),每个数据页都需要修改,所以你会看到这个import语句的执行是需要一些时间的.
                    *_  当然,如果是相比于逻辑导入的方法,import语句的耗时是非常短的
            *[#lightblue] 对比
                * 物理拷贝
                    *_ 速度最快,尤其对大表拷贝.误删表的情况,用备份恢复出误删之前的临时库,然后再把临时库中的表拷贝到生产库上,是恢复数据最快的方法
                    *_ 但是,这种方法的使用也有一定的局限性:必须是全表拷贝,不能只拷贝部分数据;
                    *_ 需要到服务器上拷贝数据,在用户无法登录数据库主机的场景下无法使用;
                    *_ 由于是通过拷贝物理文件实现的,源表和目标表都是使用InnoDB引擎时才能使用.
                * 用mysqldump生成包含INSERT语句文件的方法
                    *_ 可以在where参数增加过滤条件,来实现只导出部分数据
                    *_ 这个方式的不足之一是,不能使用join这种比较复杂的where条件写法.
                * 用select…into outfile
                    *_ 最灵活的,支持所有的SQL写法.
                    *_ 但缺点之一就是,每次只能导出一张表的数据,而且表结构也需要另外的语句单独备份
        *[#lightgreen] grant之后要跟着flush privileges吗
        *[#lightgreen] 要不要使用分区表
            *_ 引擎层是N个表,server层是1个表
            *_ 分区表gap-lock是在引擎层单表上
            *_ 每当第一次访问分区表时,会依次打开所有分区
            *_ MDL锁会锁住所有的分区
        *[#lightgreen] 答疑三:说一说这些好问题
        *[#lightgreen] 自增id用完怎么办
@endmindmap